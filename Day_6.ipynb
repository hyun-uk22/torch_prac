{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8276af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([3, 2])\n",
      "\n",
      "Output:\n",
      "tensor([[2.2368, 1.2292, 0.4714, 0.3864, 0.1309, 0.9838],\n",
      "        [4.4919, 2.1970, 0.4469, 0.5285, 0.3401, 2.4777],\n",
      "        [6.7469, 3.1648, 0.4224, 0.6705, 0.5493, 3.9716]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "\n",
      "Output shape: torch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "tensor_A = torch.tensor([[1,2], [3,4], [5,6]], dtype=torch.float32)\n",
    "#tensor_B = torch.tensor([[7,10],[8,11],[9,12]], dtype=torch.float32)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "linear = torch.nn.Linear(in_features=2, out_features=6)\n",
    "x = tensor_A\n",
    "output = linear(x)\n",
    "print(f\"Input shape: {x.shape}\\n\")\n",
    "print(f\"Output:\\n{output}\\n\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e0dde88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
      "torch.int64\n",
      "Minimum: 0\n",
      "Maximum: 90\n",
      "Mean: 45.0\n",
      "Sum: 450\n",
      "\n",
      "tensor(90)\n",
      "tensor(0)\n",
      "tensor(45.)\n",
      "tensor(450)\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(0,100,10)\n",
    "print(x)\n",
    "print(x.dtype)\n",
    "\n",
    "print(f\"Minimum: {x.min()}\")\n",
    "print(f\"Maximum: {x.max()}\")\n",
    "print(f\"Mean: {x.type(torch.float32).mean()}\") # float datatype이 아니면 작동하지 않음  # x.mean() <- error\n",
    "print(f\"Sum: {x.sum()}\\n\")\n",
    "\n",
    "print(torch.max(x))\n",
    "print(torch.min(x))\n",
    "print(torch.mean(x.type(torch.float32)))\n",
    "print(torch.sum(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80616840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: tensor([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
      "Index where max value occurs: 8\n",
      "Index where min value occurs: 0\n"
     ]
    }
   ],
   "source": [
    "# torch.argmax(), torch.argmin() <- 각각 최대값, 최소값의 인덱스를 반환  (softmax activation function(활성화함수)을 사용할 때 유용함)\n",
    "tensor = torch.arange(10,100,10)\n",
    "print(f\"Tensor: {tensor}\")\n",
    "print(f\"Index where max value occurs: {tensor.argmax()}\")\n",
    "print(f\"Index where min value occurs: {tensor.argmin()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb107ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "tensor([10., 20., 30., 40., 50., 60., 70., 80., 90.], dtype=torch.float16)\n",
      "tensor([10, 20, 30, 40, 50, 60, 70, 80, 90], dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "# torch.Tensor.type(dtype=None)을 사용하면 텐서의 자료형 변경 가능, dtype 매개변수는 사용자가 원하는 자료형을 지정\n",
    "# 텐서를 생성했을 때 기본 데이터타입은 torch.float32\n",
    "tensor = torch.arange(10.,100.,10.)\n",
    "print(tensor.dtype)\n",
    "\n",
    "tensor_float16 = tensor.type(torch.float16)\n",
    "print(tensor_float16)\n",
    "\n",
    "tensor_int8 = tensor_float16.type(torch.int8)\n",
    "print(tensor_int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dbee7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "tensor([1, 2, 3]) \n",
      "\n",
      "torch.Size([1, 3])\n",
      "tensor([[1, 2, 3]]) \n",
      "\n",
      "torch.Size([1, 1, 3])\n",
      "tensor([[[1, 2, 3]]])\n"
     ]
    }
   ],
   "source": [
    "# 실제 값을 바꾸지 않으면서 텐서들의 차원을 바꾸고자 할 때 (change or reshape)\n",
    "# reshaping, stacking, squeezing and unsqueezing\n",
    "# torch.reshape(input, shape)  #input을 원하는 형태(shape)으로 재배열\n",
    "# Tensor.view(shape)  # 기존 텐서의 데이터를 유지하면서 다른 모양의 뷰를 반환   # 다른 모양의 뷰 : 기존 텐서의 메모리를 그대로 사용하면서 shape만 바꾼 텐서\n",
    "# torch.stack(tensors, dim=0)  # 같은 크기의 텐서들을 새로운 차원으로 쌓음\n",
    "# torch.squeeze(input)  # 텐서의 모든 크기 1인 차원을 제거\n",
    "# torch.unsqueeze(input, dim)  # 지정한 위치 dim에 크기 1인 새로운 차원을 추가\n",
    "# torch.permute(input, dims)  # 텐서의 차원 순서를 바꿈(재배열)\n",
    "\n",
    "# torch.unsqueeze()\n",
    "x = torch.tensor([1, 2, 3])  # shape: (3,)\n",
    "print(x.shape)\n",
    "print(x,\"\\n\")\n",
    "\n",
    "unsqueezed = torch.unsqueeze(x, 0)  # 0번 차원에 1 추가 → (1, 3)\n",
    "print(unsqueezed.shape) \n",
    "print(unsqueezed,\"\\n\")\n",
    "\n",
    "unsqueezed = torch.unsqueeze(unsqueezed, 1)  # 1번 차원에 1 추가 → (3, 1)\n",
    "print(unsqueezed.shape)\n",
    "print(unsqueezed)\n",
    "\n",
    "# torch.permute()\n",
    "x = torch.randn(2, 3, 4)  # shape: (2, 3, 4)\n",
    "print(x)\n",
    "print(x.shape)\n",
    "\n",
    "permuted = torch.permute(x, (1, 0, 2))  # → (3, 2, 4)\n",
    "print(permuted)\n",
    "print(permuted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fb7a57ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4., 5., 6., 7.])\n",
      "torch.Size([7])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.arange(1.,8.)\n",
    "print(x)\n",
    "print(x.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cea627aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3., 4., 5., 6., 7.]]) torch.Size([1, 7])\n"
     ]
    }
   ],
   "source": [
    "x_reshaped = x.reshape(1,7)\n",
    "print(x_reshaped, x_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7085f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3., 4., 5., 6., 7.]]) torch.Size([1, 7])\n"
     ]
    }
   ],
   "source": [
    "z = x.view(1,7) # 다른 모양의 뷰 : 기존 텐서의 메모리를 그대로 사용하면서 shape만 바꾼 텐서\n",
    "print(z, z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcdd88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 2., 3., 4., 5., 6., 7.]]) tensor([5., 2., 3., 4., 5., 6., 7.])\n"
     ]
    }
   ],
   "source": [
    "z[:,0]=5  # 기존 텐서의 메모리를 그대로 사용하기 때문에 z를 빠구면 x(original)도 바뀜\n",
    "print(z,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfc0a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 2., 3., 4., 5., 6., 7.])\n",
      "torch.Size([7]) \n",
      "\n",
      "tensor([[5., 2., 3., 4., 5., 6., 7.],\n",
      "        [5., 2., 3., 4., 5., 6., 7.],\n",
      "        [5., 2., 3., 4., 5., 6., 7.],\n",
      "        [5., 2., 3., 4., 5., 6., 7.]])\n",
      "torch.Size([4, 7]) \n",
      "\n",
      "tensor([[5., 5., 5., 5.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [4., 4., 4., 4.],\n",
      "        [5., 5., 5., 5.],\n",
      "        [6., 6., 6., 6.],\n",
      "        [7., 7., 7., 7.]])\n",
      "torch.Size([7, 4])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(x.shape,\"\\n\")\n",
    "\n",
    "x_stacked = torch.stack([x,x,x,x], dim=0) #dim은 새로운 차원을 어느 인덱스에 넣을지\n",
    "print(x_stacked)\n",
    "print(x_stacked.shape,\"\\n\")\n",
    "\n",
    "x_stacked = torch.stack([x,x,x,x], dim=1)\n",
    "print(x_stacked)\n",
    "print(x_stacked.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "89e6dff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([[5., 2., 3., 4., 5., 6., 7.]])\n",
      "Previous shape: torch.Size([1, 7])\n",
      "\n",
      "New tensor: tensor([5., 2., 3., 4., 5., 6., 7.])\n",
      "New shape: torch.Size([7])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Previous tensor: {x_reshaped}\")\n",
    "print(f\"Previous shape: {x_reshaped.shape}\")\n",
    "\n",
    "# x_reshaped에서 추가 차원(extra demension) 제거\n",
    "x_squeezed = x_reshaped.squeeze()\n",
    "print(f\"\\nNew tensor: {x_squeezed}\")\n",
    "print(f\"New shape: {x_squeezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "308f885f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([5., 2., 3., 4., 5., 6., 7.])\n",
      "Previous shape: torch.Size([7])\n",
      "\n",
      "New tensor: tensor([[5., 2., 3., 4., 5., 6., 7.]])\n",
      "New shape: torch.Size([1, 7])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Previous tensor: {x_squeezed}\")\n",
    "print(f\"Previous shape: {x_squeezed.shape}\")\n",
    "\n",
    "# 추가 차원(extra dimension) 추가\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
    "print(f\"\\nNew tensor: {x_unsqueezed}\")\n",
    "print(f\"New shape: {x_unsqueezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e10b8b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: torch.Size([224, 224, 3])\n",
      "New shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# torch.permute()를 사용하면 axes(축)의 순서를 바꿀 수 있음, 이 함수는 input텐서를 새로운 축 순서를 갖는 뷰(view)로 변환\n",
    "x_original = torch.rand(size=(224,224,3))\n",
    "\n",
    "x_permuted = x_original.permute(2,0,1)\n",
    "\n",
    "print(f\"Previous shape: {x_original.shape}\")\n",
    "print(f\"New shape: {x_permuted.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2b00530b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]]) torch.Size([1, 3, 3]) \n",
      "\n",
      "First square bracket:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "Second square bracket: tensor([1, 2, 3])\n",
      "Third square bracket: 1\n",
      "\n",
      "tensor([[1, 2, 3]])\n",
      "tensor([[2, 5, 8]])\n",
      "tensor([5])\n",
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# indexing (selecting data from tensors), 텐서로부터 특정 데이터만 선택하기를 원할 때\n",
    "import torch\n",
    "x= torch.arange(1,10).reshape(1,3,3)\n",
    "print(x, x.shape,\"\\n\")\n",
    "\n",
    "print(f\"First square bracket:\\n{x[0]}\")\n",
    "print(f\"Second square bracket: {x[0][0]}\")\n",
    "print(f\"Third square bracket: {x[0][0][0]}\\n\")\n",
    "\n",
    "# 콜론(:)을 사용하면 해당 차원의 모든 값을 지정할 수 있고, 그 뒤에 쉼표를 사용해서 다른 차원의 값을 추가로 지정 가능\n",
    "print(x[:,0])\n",
    "print(x[:,:,1])\n",
    "print(x[:,1,1])\n",
    "print(x[0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6b31a1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3. 4. 5. 6. 7.]\n",
      "tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#PyTorch tensors & Numpy\n",
    "# torch.from_numpy(ndarray) - Numpy array -> Pytorch tensor\n",
    "# torch.Tensor.numpy()- Pytorch tensor -> Numpy array\n",
    "import torch\n",
    "import numpy as np\n",
    "array = np.arange(1.0,8.0)  \n",
    "tensor = torch.from_numpy(array) \n",
    "print(array)\n",
    "print(tensor)\n",
    "# numpy arrays는 default로 데이터타입이 float64임, pytorch tensor로 바꿔도 데이터 타입이 동일하게 유지됨  \n",
    "# pytorch 계산은 default로 flaot32를 사용함\n",
    "# Numpy array -> pytorch tensor(float32) : torch.from_numpy(array).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0026826b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 3. 4. 5. 6. 7. 8.]\n",
      "tensor([1., 1., 1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "array = array + 1\n",
    "#tensor = tensor +1\n",
    "print(array)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "96f48d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1. 1. 1.] float32 \n",
      "\n",
      "tensor([2., 2., 2., 2., 2., 2., 2.])\n",
      "[1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Tensor to Numpy array\n",
    "tensor = torch.ones(7)\n",
    "numpy_tensor = tensor.numpy()\n",
    "print(tensor)\n",
    "print(numpy_tensor, numpy_tensor.dtype, \"\\n\")\n",
    "\n",
    "tensor = tensor+1\n",
    "print(tensor)\n",
    "print(numpy_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879b1303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 재현 가능성 Reproducibility\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
