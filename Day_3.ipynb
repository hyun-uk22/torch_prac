{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5156f133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f28e5683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size =64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size = 64, shuffle=True)\n",
    "\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img,cmap = \"gray\")  # matplotlib의 시각화 함수\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f49a6266",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "ds = datasets.FashionMNIST(\n",
    "    root = \"data\",\n",
    "    train=True,\n",
    "    download = True,\n",
    "    transform = ToTensor(),\n",
    "    target_transform = Lambda(lambda y:torch.zeros(10, dtype = torch.float).scatter_(0,torch.tensor(y),value=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a688ee55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17a48cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,10),\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "    \n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f55b9fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([5], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1,28,28, device = device)  # 28*28 크기의 흑백 이미지 1장 랜덤 생성\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)  # logits를 확률 값으로 변환 (Softmax 함수 : 각 클래스에 대한 값을 0~1 사이의 확류로 바꾸고 총합을 1이 되게 만듦)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7187680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# 모델 계층\n",
    "input_image = torch.rand(3,28,28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebc4d43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n",
      "torch.Size([3, 20])\n",
      "Before ReLU: tensor([[-0.0597, -0.5945,  0.1571, -0.3142,  0.6179,  0.5900, -0.1318,  0.3048,\n",
      "          0.1559, -0.9571,  0.1015, -0.0594,  0.2620,  0.4942, -0.0289, -0.1853,\n",
      "         -0.3559, -0.0658, -0.4349, -0.2508],\n",
      "        [-0.0875, -0.5301,  0.3015, -0.0613,  0.7265,  0.4976, -0.0883,  0.2290,\n",
      "          0.0316, -0.8860,  0.1203,  0.4620,  0.1643, -0.0567, -0.2489,  0.0890,\n",
      "         -0.3189,  0.0486, -0.3603, -0.3761],\n",
      "        [ 0.1708, -0.5272,  0.2507, -0.2023,  0.5128,  0.3885, -0.0133, -0.0792,\n",
      "          0.1003, -0.9706,  0.2061,  0.2506, -0.0528, -0.1218, -0.2759,  0.0212,\n",
      "         -0.1780, -0.2100, -0.7066,  0.1694]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "After ReLU: tensor([[0.0000, 0.0000, 0.1571, 0.0000, 0.6179, 0.5900, 0.0000, 0.3048, 0.1559,\n",
      "         0.0000, 0.1015, 0.0000, 0.2620, 0.4942, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.3015, 0.0000, 0.7265, 0.4976, 0.0000, 0.2290, 0.0316,\n",
      "         0.0000, 0.1203, 0.4620, 0.1643, 0.0000, 0.0000, 0.0890, 0.0000, 0.0486,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1708, 0.0000, 0.2507, 0.0000, 0.5128, 0.3885, 0.0000, 0.0000, 0.1003,\n",
      "         0.0000, 0.2061, 0.2506, 0.0000, 0.0000, 0.0000, 0.0212, 0.0000, 0.0000,\n",
      "         0.0000, 0.1694]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())\n",
    "\n",
    "layer1 = nn.Linear(in_features = 28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())\n",
    "\n",
    "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed4d483e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[-0.0021,  0.0007,  0.0290,  ...,  0.0108, -0.0119, -0.0275],\n",
      "        [ 0.0272, -0.0066,  0.0233,  ..., -0.0348,  0.0226, -0.0332]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([ 0.0204, -0.0081], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 2.1534e-03, -1.1703e-02,  4.0372e-02,  ..., -1.2118e-02,\n",
      "          2.2488e-03,  2.6670e-02],\n",
      "        [ 9.9130e-05,  2.7478e-02, -3.9091e-03,  ..., -4.0509e-02,\n",
      "         -4.2636e-02, -4.0967e-02]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([0.0178, 0.0234], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[-0.0329, -0.0127,  0.0253,  ...,  0.0146, -0.0334, -0.0419],\n",
      "        [-0.0229, -0.0094, -0.0268,  ...,  0.0257,  0.0212, -0.0352]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([0.0204, 0.0390], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20,10)\n",
    ")\n",
    "input_image = torch.rand(3,28,28)\n",
    "logits = seq_modules(input_image)\n",
    "\n",
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)\n",
    "\n",
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fceba3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient function for z = <AddBackward0 object at 0x0000020E2BA8A470>\n",
      "Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward0 object at 0x0000020E4537FEE0>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.ones(5)   #input tensor     \n",
    "y = torch.zeros(3)   #expected output    \n",
    "w = torch.randn(5,3,requires_grad=True)  # requires_grad = True는 텐서를 생성할 때 설정하거나, x.requires_grad_(True) 메소드를 사용하여 나중에 설정 가능\n",
    "b = torch.randn(3,requires_grad=True)  #requires_grad는 생략이 가능한데, False가 기본적으로 설정되어 있음, 이러한 것들은 고정된 매개변수\n",
    "z= torch.matmul(x,w)+b\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z,y)\n",
    "\n",
    "print(f\"Gradient function for z = {z.grad_fn}\")\n",
    "print(f\"Gradient function for loss = {loss.grad_fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "936ed838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3052, 0.0055, 0.1681],\n",
      "        [0.3052, 0.0055, 0.1681],\n",
      "        [0.3052, 0.0055, 0.1681],\n",
      "        [0.3052, 0.0055, 0.1681],\n",
      "        [0.3052, 0.0055, 0.1681]])\n",
      "tensor([0.3052, 0.0055, 0.1681])\n"
     ]
    }
   ],
   "source": [
    "loss.backward()  # 해당 메서드를 통해서 w와 b에 대해 미분 / 원래 w와 b의 변수에 grad 속성의 초기값은 None이었지만, 해당 메서드를 호출하면서 PyTorch가 loss를 각 파라미터에 대해 미분하여 grad 속성에 기울기 값이 저장됨\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c5286ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x,w)+b\n",
    "print(z.requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = torch.matmul(x,w)+b\n",
    "print(z.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab89cee7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
